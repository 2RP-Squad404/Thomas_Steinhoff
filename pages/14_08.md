# Relatório de Estudos

**Nome do Estagiário:** Thomas Ventura Steinhoff
**Data:** 14/08/2024

## Módulos/Etapas Feitas:

---
- Modelagem de dados
- Análise de dados
- BigQuery
- Mensageria
---
- Analíticas
- PySpark
---

## Resumo dos módulos

A modelagem de dados abrange todas as etapas, desde a criação do modelo de armazenamento dos dados até sua manutenção. O processo inicial de criação de um banco de dados consiste em algumas etapas de preparação. O modelo conceitual representa uma visão mais abstrata, focada na organização das relações e estruturas, sendo o Diagrama ER a metodologia mais comum. O modelo lógico aprofunda-se em detalhes, como tipos de dados e uma abordagem mais técnica, embora ainda sem aplicações práticas. O modelo físico é a concretização do design do banco de dados, onde as decisões técnicas são aplicadas para garantir eficiência, segurança e integridade dos dados. É necessário também realizar uma preparação cuidadosa antes e durante a idealização dos modelos, como a coleta de dados para a identificação dos requisitos, além da manutenção constante.

A análise de dados trata de todas as questões relacionadas à qualidade dos dados, bem como de prepará-los para futuras análises e consultas, o que inclui a limpeza e formatação dos dados, eliminação de duplicatas e tratamento de valores ausentes. A análise de dados se divide em categorias que visam diferentes formas de manipular um banco de dados. A análise descritiva foca em descrever e visualizar dados de forma estatística. A análise diagnóstica trata de correlações e causalidades, reconhecendo padrões ou comportamentos. A análise preditiva utiliza fundamentos de machine learning para fazer previsões. A análise prescritiva oferece estratégias para conduzir processos e decisões.

Em suma, a modelagem de dados estabelece a base estrutural para o armazenamento e organização eficiente dos dados, enquanto a análise de dados utiliza essa estrutura para extrair insights valiosos. Juntas, elas garantem que os dados sejam não apenas armazenados de forma otimizada, mas também preparados e interpretados de maneira a apoiar a tomada de decisões estratégicas.

O Google BigQuery é um serviço de armazenamento e análise de dados em larga escala do Google Cloud Platform, que permite consultas SQL rápidas em conjuntos de dados muito grandes. Oferece análise em tempo real e se integra facilmente com outras ferramentas do Google Cloud e soluções de Business Intelligence. As diversas facilidades oferecidas pelo Google têm como objetivo automatizar a gestão da infraestrutura, escalabilidade e outros aspectos do banco de dados, permitindo que o usuário se concentre na análise de dados. Entre seus serviços, destacam-se o poder de processamento em massa de forma rápida e paralela, além da flexibilidade tanto em aplicações quanto em custos.

Toda a magnitude da engenharia de dados requer recursos para modelar e manipular tanta informação. Ferramentas como PySpark, Apache Beam e BigQuery são utilizadas para tratar esses dados. Esses recursos são uma extensão das ferramentas SQL e NoSQL, que são como tornos mecânicos: você tem controle manual sobre o processamento, mas precisa tratar cada peça de informação individualmente. Já ferramentas analíticas como PySpark e Apache Spark são como tornos CNC: permitem automatizar e lidar com tarefas complexas de forma mais eficiente, mas exigem que você aprenda a programá-las. Assim, há uma troca entre controle manual e automação, com um custo inicial de aprendizado.

---
A comunicação de dados em redes de computadores envolve o compartilhamento de mensagens, que podem ser comparadas a "pacotes" de informações. Esses pacotes seguem protocolos específicos de acordo com o tipo de dados que está sendo trocado entre diferentes pontos e sistemas. A mensageria, por sua vez, apresenta uma abordagem distinta, pois permite a troca de informações de forma assíncrona e desacoplada, sem exigir uma conexão constante. Isso oferece benefícios como resiliência, garantias de entrega e maior flexibilidade, facilitando tanto a manutenção quanto a escalabilidade do sistema.

Os modelos de mensageria estruturam a comunicação de mensagens em sistemas distribuídos, atendendo a diferentes necessidades de interação entre componentes. No modelo Pub/Sub, por exemplo, as mensagens são enviadas para um tópico e disseminadas para múltiplos assinantes simultaneamente, ideal para cenários em que várias partes precisam receber a mesma informação. Já no modelo Tópicos/Filas, as mensagens são distribuídas para todos os assinantes em um tópico ou enfileiradas para serem processadas por um único consumidor, garantindo uma comunicação ordenada e equilibrada.

O Google Cloud Pub/Sub é um serviço de mensageria gerenciado que se destaca por sua integração nativa com outros serviços da Google Cloud Platform. Ele facilita a comunicação assíncrona em sistemas distribuídos, permitindo a publicação e consumo de mensagens de forma escalável e resiliente. O Pub/Sub diferencia-se por sua escalabilidade automática, baixa latência e garantia de durabilidade das mensagens, características que o tornam ideal para aplicações que exigem alta performance e confiabilidade. Quando utilizado em conjunto com outras ferramentas da Google Cloud, como Google Cloud Functions, Dataflow e BigQuery, oferece uma solução completa para construir e gerenciar sistemas distribuídos na nuvem.

**Recursos Utilizados:**

- Google Cloud Plataform
- Docker Desktop
- Zepellin
- MinIo